<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.w3.org/2002/06/xhtml2/ http://www.w3.org/MarkUp/SCHEMA/xhtml2.xsd" xmlns:epub="http://www.idpf.org/2007/ops">
<head>
<link href="Styles/Style02.css" rel="stylesheet" type="text/css" />
<link href="Styles/Style03.css" rel="stylesheet" type="text/css" />

<style type="text/css">body{margin:1em;background-color:transparent!important;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style></head>
<body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Options to correct the incorrect queue</h1>
                </header>
            
            <article>
                
<p>What should we do? Well, it turns out there's lots of options in the literature. Hart, McKenney, Brown and Walpole's 2007 <em>Performance of Memory Reclamation for Lockless Synchronization</em> discusses four, along with references to their originating papers:</p>
<ul>
<li>
<p><strong>Quiescent-state-based reclamation</strong> (<strong>QSRB</strong>): The application's signal quiescent'periods in which reclamation is allowed</p>
</li>
<li>
<p><strong>Epoch-based reclamation</strong> (<strong>EBR</strong>): The applications make use of structures that determine when reclamation is allowed by moving memory through epochs</p>
</li>
<li>
<p><strong>Hazard-pointer-based reclamation</strong> (<strong>HPBR</strong>): Threads cooperate and signal pointers as being hazardous for reclamation</p>
</li>
<li>
<p><strong>Lock-free reference counting (LFRC</strong>): Pointers carry an atomic counter of uses alongside them, which threads use to determine safe reclamation periods</p>
</li>
</ul>
<p>Quiescent state reclamation works by having threads that operate on a shared concurrent structure signal that have entered a <em>quiescent state</em> for a period of time, meaning that for the signaled state the thread does not claim any stake over a reference from inside the shared structure. A separate reclamation actor, which may be the structure itself or a thread in a quiescent state, searched for <em>grace periods</em> in which it's safe to reclaim storage, either because all threads have gone quiescent or because some relevant subsets have. It's quite tricky and involves peppering your code with notifications of entering and exiting quiescent states. Hart et al note that this reclamation method was commonly used in the Linux kernel at the time of writing, which remains true at the time of <em>this</em> writing. Interested readers are referred to the available literature on the Linux kernel's read-copy update mechanism. The key difficulty of QSRB as a technique is that it's not always clear in user-space when a natural quiescent period exists; if you signal one incorrectly you're going to get data-races. Context switches in an operating system are a natural quiescent period—the relevant contexts won't be manipulating anything until they get called back in—but it's less clear to me in our queue where such a period would comfortably exist. The benefit of QSRB is that it's a very <em>fast</em> technique, requiring less thread synchronization than any of the other methods below.</p>
<p>Epoch-based reclamation is similar to QSRB, except that it's application independent. That is, the application interacts with storage through an intermediary layer and this layer stores enough information to decide when a grace period has come. In particular, every thread ticks a flag, indicating that it means to interact with shared data, interacts, and then ticks the flag the other direction on its way out. The number of flag cycles is referred to as an 'epoch'. Once shared data has gone through enough epochs, the thread will attempt to reclaim the storage. This method has the benefit of being more automatic than QSRB—the application developer uses specially designed intermediary types—but has the downside of requiring some synchronization on either side of the data access—those flag ticks. (The paper actually introduces a fifth, new epoch-based reclamation, which improves on epoch-based replication but does require hints from the application developer. In some sense, it is an EBR/QSRB hybrid approach.)</p>
<p>The hazard pointer reclamation scheme is entirely data structure dependent. The idea is that every involved thread will keep a collection of hazard pointers, one for each lockless operation it intended to perform. This thread-local collection of hazard pointers is mirrored into some reclamation system—perhaps a special-purpose garbage collector or plug-in allocator—and this system is able to check the status of the hazard pointers. When a thread is intended to perform a lockless operation on some shared data, it signals the hazard pointer as protected, disallowing its reclamation. When the thread is done, it signals that the shared data is no longer protected. Depending on context, the shared data may now be free for reclamation or may be subject to later reclamation. Like EBR, HPBR requires access to shared data through special structures and has overheads in terms of synchronization. Also, there maybe be a higher burden of implementation compared to EBR, but less than QSRB. Harder yet, if your data structure passes references to its internal storage, that also requires a hazard pointer. The more threads, the more hazard pointer lists you require. Memory overheads can get non-trivial real quick. Compared to grace period approaches, hazard pointers can be much faster at reclaiming memory, due to there being no need to search for a time when a reference is not hazardous. It is or it isn't. HPBR has higher overheads per operation and higher memory requirements overall, but is potentially better at reclamation. That's a non-trivial detail. If QSBR or EBR are run on systems where allocation blocks the CPU, it's possible for these methods to <em>never</em> find a grace period, eventually exhausting system memory.</p>
<p>The last of the bunch is atomic reference counting, akin to <span>standard library</span>'s <kbd>Arc</kbd> but for atomics. This method is not especially fast, incurring a cost per access to the reference counter as well as the branch on that counter, but it is simple and reclamation occurs promptly.</p>
<p>Aside from reference counting, each of these methods are tricky to implement. But we're in luck; the crate ecosystem has an implementation of epoch-based reclamation <em>and</em> hazard pointer reclamation. The relevant libraries are crossbeam (<a href="https://crates.io/crates/crossbeam">https://crates.io/crates/crossbeam</a>) and conc (<a href="https://crates.io/crates/conc">https://crates.io/crates/conc</a>). We'll discuss them in great detail in the next chapter. Crossbeam aims to be the <kbd>libcds</kbd> (<a href="https://github.com/khizmax/libcds">https://github.com/khizmax/libcds</a>) of Rust and has a Michael and Scott queue already implemented for us. Let's give it a spin. The relevant file is <kbd>src/bin/crossbeam_queue_spin.rs</kbd>:</p>
<pre>extern crate crossbeam;

use crossbeam::sync::MsQueue;
use std::sync::Arc;
use std::thread;

fn main() {
    let q = Arc::new(MsQueue::new());

    let mut jhs = Vec::new();

    for _ in 0..4 {
        let q = Arc::clone(&amp;q);
        jhs.push(thread::spawn(move || {
            let mut i = 0;
            loop {
                q.push(i);
                i += 1;
                q.pop();
            }
        }))
    }

    for jh in jhs {
        jh.join().unwrap();
    }
}</pre>
<p>This is fairly similar to <kbd>queue_spin</kbd>, save that <kbd>enq</kbd> is now push and <kbd>deq</kbd> is <kbd>pop</kbd>. It's worth noting as well that <kbd>MsQueue::pop</kbd> is blocking. The mechanism for that is very neat; we'll discuss that in the next chapter.</p>


            </article>

            
        </section>
    </div></body>
</html>